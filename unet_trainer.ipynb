{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# tf.enable_eager_execution()\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import  layers\n",
    "from tensorflow.keras.layers import Conv2D, Dropout, MaxPooling2D, UpSampling2D, Concatenate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../lib/')\n",
    "from help_functions import *\n",
    "\n",
    "#function to obtain data for training/testing (validation)\n",
    "# from extract_patches import get_data_training\n",
    "sys.path.insert(0, '../lib/networks/')\n",
    "# from fully_conv import get_fully_conv_unet as net_\n",
    "# from fully_conv import attend\n",
    "from preprocessing import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.6-tf\n"
     ]
    }
   ],
   "source": [
    "print(tf.keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_path = 'experiments/'\n",
    "exp_name = 'exp1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train images/masks shape:\n",
      "(20, 1, 565, 565)\n",
      "train images range (min-max): 0.0 - 1.0\n",
      "train masks are within 0-1\n",
      "\n",
      "patches per full image: 1500\n",
      "\n",
      "train PATCHES images/masks shape:\n",
      "(30000, 1, 128, 128)\n",
      "train PATCHES images range (min-max): 0.00784313725490196 - 1.0\n",
      "(30000, 1, 128, 128)\n",
      "128 128 1\n",
      "......DONE......\n"
     ]
    }
   ],
   "source": [
    "train_img, label_img = preprocessing(exp_path+exp_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((30000, 1, 128, 128), (30000, 16384, 2))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_img.shape, label_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(chan_out):\n",
    "    chan = 'channels_first'\n",
    "    return keras.Sequential([        \n",
    "        Conv2D(chan_out, (3, 3), activation='relu', padding='same',data_format=chan),\n",
    "        Conv2D(chan_out, (3, 3), activation='relu', padding='same',data_format=chan)\n",
    "    ])\n",
    "\n",
    "def up_block(chan_out,input_, block):\n",
    "    chan = 'channels_first'\n",
    "    upsample = layers.UpSampling2D((2,2),data_format=chan)(input_)\n",
    "    upconv = layers.Conv2DTranspose(chan_out,(3,3),padding='same',data_format=chan)(upsample)\n",
    "    concat = Concatenate(axis=1)([block, upconv])\n",
    "    return conv_block(chan_out)(concat)\n",
    "\n",
    "\n",
    "def get_unet(n_ch,patch_height, patch_width, debug=False):\n",
    "    chan = 'channels_first'\n",
    "    inputs = keras.Input(shape=(n_ch, patch_height, patch_width))\n",
    "\n",
    "    if debug : print(inputs.shape)\n",
    "        \n",
    "    #+++++++++++++++++++++++++++++++++++++++++++++++++++    \n",
    "    #EDIT HERE \n",
    "    #+++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "    #encode\n",
    "    block1 = conv_block(64)(inputs) # ------------->to down1\n",
    "    maxPool1 = MaxPooling2D((2, 2), data_format=chan)(block1)\n",
    "    \n",
    "    block2 = conv_block(128)(maxPool1) #----------->to down2\n",
    "    maxPool2 = MaxPooling2D((2, 2), data_format=chan)(block2)\n",
    "   \n",
    "    block3 = conv_block(256)(maxPool2) #----------->to down3\n",
    "    maxPool3 = MaxPooling2D((2, 2), data_format=chan)(block3)\n",
    "    \n",
    "    block4 = conv_block(512)(maxPool3) #----------->to down4\n",
    "    maxPool4 = MaxPooling2D((2, 2), data_format=chan)(block4)\n",
    "   \n",
    "    #bottom\n",
    "    block5 = conv_block(1024)(maxPool4) # ----------> bottom\n",
    "    \n",
    "    #decode\n",
    "    down4 = up_block(512,block5,block4)\n",
    "    down3 = up_block(256, down4,block3)\n",
    "    down2 = up_block(128, down3,block2)\n",
    "    down1 = up_block(64, down2,block1)\n",
    "    down1 = Dropout(.5)(down1)\n",
    "    \n",
    "    if debug : print(down1.shape)\n",
    "    \n",
    "    #+++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "    \n",
    "    conv1x1 = Conv2D(2, (1, 1), activation='relu',padding='same',data_format=chan)(down1)\n",
    "\n",
    "    conv1x1 = layers.Reshape((2,patch_height*patch_width))(conv1x1)\n",
    "    \n",
    "    conv1x1 = layers.Permute((2,1))(conv1x1)\n",
    "\n",
    "    out = layers.Activation('softmax')(conv1x1)\n",
    "       \n",
    "    model = keras.models.Model(inputs=inputs, outputs=out)\n",
    "    print(model.summary())\n",
    "\n",
    "    opt = keras.optimizers.Adam(lr=0.01, beta_1=0.9, beta_2=0.999, epsilon=0.1, decay=0.0)\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 1, 128, 128)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential (Sequential)         (None, 64, 128, 128) 37568       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 64, 64, 64)   0           sequential[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       (None, 128, 64, 64)  221440      max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 128, 32, 32)  0           sequential_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "sequential_2 (Sequential)       (None, 256, 32, 32)  885248      max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 256, 16, 16)  0           sequential_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "sequential_3 (Sequential)       (None, 512, 16, 16)  3539968     max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 512, 8, 8)    0           sequential_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "sequential_4 (Sequential)       (None, 1024, 8, 8)   14157824    max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d (UpSampling2D)    (None, 1024, 16, 16) 0           sequential_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose (Conv2DTranspo (None, 512, 16, 16)  4719104     up_sampling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 1024, 16, 16) 0           sequential_3[0][0]               \n",
      "                                                                 conv2d_transpose[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "sequential_5 (Sequential)       (None, 512, 16, 16)  7078912     concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 512, 32, 32)  0           sequential_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 256, 32, 32)  1179904     up_sampling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 512, 32, 32)  0           sequential_2[0][0]               \n",
      "                                                                 conv2d_transpose_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "sequential_6 (Sequential)       (None, 256, 32, 32)  1769984     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 256, 64, 64)  0           sequential_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 128, 64, 64)  295040      up_sampling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 256, 64, 64)  0           sequential_1[0][0]               \n",
      "                                                                 conv2d_transpose_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "sequential_7 (Sequential)       (None, 128, 64, 64)  442624      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 128, 128, 128 0           sequential_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTrans (None, 64, 128, 128) 73792       up_sampling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 128, 128, 128 0           sequential[0][0]                 \n",
      "                                                                 conv2d_transpose_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "sequential_8 (Sequential)       (None, 64, 128, 128) 110720      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 64, 128, 128) 0           sequential_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 2, 128, 128)  130         dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 2, 16384)     0           conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "permute (Permute)               (None, 16384, 2)     0           reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 16384, 2)     0           permute[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 34,512,258\n",
      "Trainable params: 34,512,258\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = get_unet(1,128,128)\n",
    "\n",
    "#save weights\n",
    "sav_path = '../'+exp_path+exp_name+'/'+exp_name\n",
    "\n",
    "checkpoints = keras.callbacks.ModelCheckpoint(filepath=sav_path+'_best_w.h5', \n",
    "                                            monitor='val_loss',verbose=2,\n",
    "                                            save_best_only=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 27000 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.24968, saving model to ../experiments/exp1/exp1_best_w.h5\n",
      " - 256s - loss: 0.3773 - acc: 0.8733 - val_loss: 0.2497 - val_acc: 0.9141\n",
      "Epoch 2/10\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.24968 to 0.16445, saving model to ../experiments/exp1/exp1_best_w.h5\n",
      " - 248s - loss: 0.2115 - acc: 0.9241 - val_loss: 0.1645 - val_acc: 0.9371\n",
      "Epoch 3/10\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.16445 to 0.14928, saving model to ../experiments/exp1/exp1_best_w.h5\n",
      " - 248s - loss: 0.1654 - acc: 0.9389 - val_loss: 0.1493 - val_acc: 0.9431\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-868e1f089b1a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m                     \u001b[0mvalidation_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                     \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m                     callbacks=[checkpoints])\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1637\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1638\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1639\u001b[0;31m           validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1641\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    213\u001b[0m           \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m           \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2984\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2985\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 2986\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   2987\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2988\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(train_img, label_img, batch_size=32,epochs=10,\n",
    "                    validation_split = 0.1, \n",
    "                    shuffle=True, verbose=2, \n",
    "                    callbacks=[checkpoints])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
